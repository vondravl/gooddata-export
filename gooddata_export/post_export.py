"""
Post-export processing functions for GoodData metadata export.
These functions run after data export to enhance or modify the exported data.

Configuration is loaded from sql/post_export_config.yaml and executed in
dependency order using topological sort.
"""

import os
import sqlite3
import yaml
import logging
from collections import defaultdict, deque
from gooddata_export.db import connect_database
from gooddata_export.config import ExportConfig

logger = logging.getLogger(__name__)


def load_post_export_config():
    """Load post-export configuration from YAML file.

    Returns:
        dict: Configuration with 'views' and 'updates' sections
    """
    config_path = os.path.join(
        os.path.dirname(os.path.abspath(__file__)), "sql", "post_export_config.yaml"
    )

    with open(config_path, "r") as f:
        return yaml.safe_load(f)


def topological_sort(items_dict):
    """Sort items by dependencies using topological sort (Kahn's algorithm).

    Args:
        items_dict: Dictionary where each item has a 'dependencies' list

    Returns:
        list: Ordered list of item names (keys from items_dict)

    Raises:
        ValueError: If circular dependencies are detected
    """
    # Build adjacency list and in-degree count
    graph = defaultdict(list)
    in_degree = defaultdict(int)
    all_items = set(items_dict.keys())

    # Initialize in-degree for all items
    for item in all_items:
        in_degree[item] = 0

    # Build graph
    for item, config in items_dict.items():
        dependencies = config.get("dependencies", [])
        for dep in dependencies:
            if dep not in all_items:
                raise ValueError(
                    f"Item '{item}' depends on '{dep}' which doesn't exist in configuration"
                )
            graph[dep].append(item)
            in_degree[item] += 1

    # Find all items with no dependencies (in-degree = 0)
    queue = deque([item for item in all_items if in_degree[item] == 0])
    result = []

    # Process queue
    while queue:
        # Sort to ensure deterministic order when multiple items have no dependencies
        current = sorted(queue)[0]
        queue.remove(current)
        result.append(current)

        # Reduce in-degree for dependent items
        for dependent in graph[current]:
            in_degree[dependent] -= 1
            if in_degree[dependent] == 0:
                queue.append(dependent)

    # Check for circular dependencies
    if len(result) != len(all_items):
        remaining = all_items - set(result)
        raise ValueError(f"Circular dependency detected. Cannot process: {remaining}")

    return result


def substitute_parameters(sql_script, parameters, config):
    """Substitute parameters in SQL script.

    Args:
        sql_script: The SQL script content
        parameters: Dict of parameter definitions from config
        config: ExportConfig instance for accessing runtime values

    Returns:
        str: SQL script with substituted parameters
    """
    if not parameters:
        return sql_script

    result = sql_script
    for param_name, param_template in parameters.items():
        # Handle special template syntax
        if param_template.startswith("{{") and param_template.endswith("}}"):
            # {{WORKSPACE_ID}} -> get actual value from config
            config_key = param_template[2:-2].strip()
            if hasattr(config, config_key):
                value = getattr(config, config_key)
                result = result.replace(f"{{{param_name}}}", str(value))
                logger.debug(f"  Substituted {{{param_name}}} with {value}")
            else:
                logger.warning(
                    f"  Config key {config_key} not found, skipping substitution"
                )
        elif param_template.startswith("$$"):
            # $${TOKEN_GOODDATA_DEV} -> replace with ${TOKEN_GOODDATA_DEV} (literal string, remove one $)
            value = param_template[1:]  # Remove one $ to get ${...}
            result = result.replace(f"{{{param_name}}}", value)
            logger.debug(f"  Substituted {{{param_name}}} with literal {value}")
        else:
            # Direct string substitution
            result = result.replace(f"{{{param_name}}}", param_template)
            logger.debug(f"  Substituted {{{param_name}}} with {param_template}")

    return result


def execute_sql_file(cursor, sql_path, parameters=None, config=None):
    """Execute a SQL file with optional parameter substitution.

    Args:
        cursor: Database cursor
        sql_path: Path to SQL file
        parameters: Optional dict of parameters to substitute
        config: Optional ExportConfig instance for parameter values

    Returns:
        bool: True if successful, False otherwise
    """
    if not os.path.exists(sql_path):
        logger.warning(f"SQL file not found: {sql_path}")
        return False

    logger.debug(f"  Executing: {os.path.basename(sql_path)}")

    with open(sql_path, "r") as f:
        sql_script = f.read()

    # Perform parameter substitution if needed
    if parameters and config:
        sql_script = substitute_parameters(sql_script, parameters, config)

    try:
        # Try to execute the entire script as a single transaction
        cursor.executescript(sql_script)
        return True
    except sqlite3.OperationalError:
        # If that fails, fall back to executing statements individually
        logger.debug("  Executing statement by statement...")
        statements = sql_script.split(";")
        for statement in statements:
            if statement.strip():
                try:
                    cursor.execute(statement)
                except sqlite3.Error as stmt_error:
                    logger.error(f"  Error: {stmt_error}")
                    logger.debug(f"  Statement: {statement[:100]}...")
                    raise
        return True
    except Exception as e:
        logger.error(f"Error executing {os.path.basename(sql_path)}: {str(e)}")
        return False


def ensure_columns_exist(cursor, table_name, required_columns):
    """Ensure required columns exist in a table, adding them if necessary.

    Args:
        cursor: Database cursor
        table_name: Name of the table
        required_columns: Dict of {column_name: column_type}
    """
    if not required_columns:
        return

    cursor.execute(f"PRAGMA table_info({table_name})")
    existing_columns = [column[1] for column in cursor.fetchall()]

    for column_name, column_type in required_columns.items():
        if column_name not in existing_columns:
            logger.debug(f"  Adding column: {table_name}.{column_name}")
            cursor.execute(
                f"ALTER TABLE {table_name} ADD COLUMN {column_name} {column_type}"
            )


def run_post_export_sql(db_path):
    """Run all post-export SQL operations on the database.

    This is the main entry point for post-export processing.
    Operations are executed in dependency order using topological sort.

    Args:
        db_path: Path to the SQLite database

    Returns:
        bool: True if all operations successful, False otherwise
    """
    logger.debug("=" * 70)
    logger.debug("POST-EXPORT PROCESSING")
    logger.debug("=" * 70)

    try:
        # Load configuration
        yaml_config = load_post_export_config()
        sql_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "sql")

        # Load export config for parameter substitution
        export_config = ExportConfig(load_from_env=True)

        # Connect to database
        conn = connect_database(db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        # Combine views, updates, and procedures for dependency sorting
        all_items = {}
        if "views" in yaml_config:
            all_items.update(yaml_config["views"])
        if "updates" in yaml_config:
            all_items.update(yaml_config["updates"])
        if "procedures" in yaml_config:
            all_items.update(yaml_config["procedures"])

        # Sort by dependencies
        try:
            execution_order = topological_sort(all_items)
        except ValueError as e:
            logger.error(f"Configuration error: {e}")
            return False

        logger.debug(
            f"Executing {len(execution_order)} operations in dependency order:"
        )
        logger.debug("-" * 70)

        # Execute each operation in order
        success_count = 0
        for item_name in execution_order:
            item_config = all_items[item_name]

            # Determine type: view, update, or procedure
            is_view = item_name in yaml_config.get("views", {})
            is_update = item_name in yaml_config.get("updates", {})
            is_procedure = item_name in yaml_config.get("procedures", {})

            if is_procedure:
                item_type = "PROCEDURE"
            elif is_view:
                item_type = "VIEW"
            else:
                item_type = "UPDATE"

            category = item_config.get("category", "unknown")

            logger.debug(f"\n[{item_type}] {item_name} ({category})")
            logger.debug(f"  Description: {item_config.get('description', 'N/A')}")

            # Show dependencies if any
            deps = item_config.get("dependencies", [])
            if deps:
                logger.debug(f"  Dependencies: {', '.join(deps)}")

            # For updates, ensure required columns exist
            if is_update:
                table_name = item_config.get("table")
                required_columns = item_config.get("required_columns", {})
                if table_name and required_columns:
                    ensure_columns_exist(cursor, table_name, required_columns)

            # Execute SQL file
            sql_file = item_config["sql_file"]
            sql_path = os.path.join(sql_dir, sql_file)

            # Get parameters for procedure items
            parameters = item_config.get("parameters", {}) if is_procedure else None

            if execute_sql_file(
                cursor, sql_path, parameters=parameters, config=export_config
            ):
                success_count += 1
                logger.debug("  âœ“ Success")
            else:
                logger.error(f"Failed to execute {item_name}")
                conn.rollback()
                conn.close()
                return False

        # Commit all changes
        conn.commit()
        conn.close()

        logger.debug("=" * 70)
        logger.debug(
            f"ALL OPERATIONS COMPLETED SUCCESSFULLY ({success_count}/{len(execution_order)})"
        )
        logger.debug("=" * 70)

        # Simple info message for regular users
        view_count = len(yaml_config.get("views", {}))
        update_count = len(yaml_config.get("updates", {}))
        procedure_count = len(yaml_config.get("procedures", {}))

        logger.info(
            f"Successfully created {view_count} views, {procedure_count} procedures, and {update_count} table updates in database"
        )

        return True

    except Exception as e:
        logger.error(f"Error during post-export processing: {str(e)}")
        return False
